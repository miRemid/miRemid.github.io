<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jetson on 狸猫窝</title><link>https://blog.thinkmoe.icu/tags/jetson/</link><description>Recent content in Jetson on 狸猫窝</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 05 Mar 2023 22:01:11 +0800</lastBuildDate><atom:link href="https://blog.thinkmoe.icu/tags/jetson/index.xml" rel="self" type="application/rss+xml"/><item><title>Jetson TX2 NX 配置笔记</title><link>https://blog.thinkmoe.icu/posts/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 05 Mar 2023 22:01:11 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</guid><description>Jetson真的好贵啊&amp;gt; &amp;lt;
tx2nx开发板
由于科研的需要，需要在边缘设备上对深度学习模型进行量化测试。实验室内刚好有闲置的Nvidia Jetson TX2开发板，所以就直接拿来测试了
原本以为在开发板上的配置会比较简单，无非就是从x86平台转换到arm上面，但实际上坑非常多例如前面提到的arm架构，其实在Jetson上面压根不是传统的arm架构，而是从armv8独立分支出来的aarch架构
虽然坑非常多，但总体上配置流程也非常简洁，基本配置过程也和x86平台上面大致相同，只是在安装的时候需要注意。本文大纲如下
烧录安装系统 安装conda虚拟环境 安装Pytorch和torchvision 安装torch2trt 安装系统 首先需要烧录镜像到开发板中，由于我这块板子在购买的时候代理商就已经烧录好了系统到固件中，因此直接开机即可
如果是裸板安装，则可以参考知乎的教程进行烧录安装
连接电源启动开发板，在安装界面中可以选择启用CPU核心的选项，默认是4核，对应的SWAP大小为2GB，可以按照自己的需求进行更改。当然，如果已经安装完了系统也可以在系统中进行修改。
tx2自带的存储大小非常小只有16GB，按需求进行扩容，我这里是外接了一块128G的SSD硬盘
安装conda虚拟环境 按照本人的习惯，需要一个虚拟环境用于区分不同项目的环境，在tx2也不例外。这里就出现了第一个坑，那就是官方的conda并不能在tx2上完美运行！ 就算你下载的是aarch架构的脚本，你在安装过程中也可能报错，又或者即使安装成功你在创建虚拟环境选择低版本的Python时也会出现错误
为了解决这个问题，我们需要使用一个修改版的conda，那就是Mambaforge。从官方的Release中下载所需要的脚本文件(注意得是aarch架构的文件！)，安装方式则和普通版本的conda如出一辙，需要注意的是安装的位置需要选择一个容量更大的硬盘上面
wget https://github.com/conda-forge/miniforge/releases/download/22.11.1-4/Mambaforge-22.11.1-4-Linux-aarch64.sh sh Mambaforge-22.11.1-4-Linux-aarch64.sh 随后创建你的第一个环境吧
conda create -n hello python=3.6 conda activate hello 安装Pytorch和torchvision 在安装Pytorch前，你需要安装Jetson的CUDA环境，默认情况下是没有的，当然在Nvidia自家产品上安装CUDA环境非常简单，不像Linux那样惹人厌。安装只需要一条命令即可
sudo apt install nvidia-jetpack 这时，查看/usr/local中应该就会出现对应的CUDA环境了，Jetpack会帮助你安装CUDA工具包、TensorRT和其他工具，你可以通过jetson_release来查看当前安装的CUDA版本
(base) tx2-1@tx2-1-desktop:/usr/local$ jetson_release Software part of jetson-stats 4.1.5 - (c) 2023, Raffaello Bonghi Model: lanai-3636 - Jetpack 4.6.1 [L4T 32.7.1] NV Power Mode: MAXP_CORE_ARM - Type: 3 jtop: - Version: 4.</description></item></channel></rss>