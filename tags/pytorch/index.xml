<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pytorch on 狸猫窝</title><link>https://blog.thinkmoe.icu/tags/pytorch/</link><description>Recent content in pytorch on 狸猫窝</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 17 Dec 2021 17:52:42 +0800</lastBuildDate><atom:link href="https://blog.thinkmoe.icu/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>使用Pytorch预训练网络获取图片特征</title><link>https://blog.thinkmoe.icu/posts/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87%E7%89%B9%E5%BE%81/</link><pubDate>Fri, 17 Dec 2021 17:52:42 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87%E7%89%B9%E5%BE%81/</guid><description>由于Carla训练过程中需要使用到图像数据，而通常深度强化学习(DRL)算法中，输入的数据都为一个 向量(Vector)，如果需要使用图像这种二维数据，通常的做法是使用一个CNN网络，提取图像的特征， 将二维数据转化为一维向量数据，这样就能够直接使用现有的DRL算法
例如在stable_baseline3中，支持MLP、CNN和 多种不同类型观测对象混合输入。对于图像数据，都使用了一个基于CNN深度卷积网络来提取特征。
在pytorch中已经有了很多优秀的CNN特征提取网络，在这里我将会使用到MobileNetV3这个网络用 于提取Carla的摄像头图片特征。
读取模型 首先需要安装torchvision这个包，里面包含了现有非常流行的图像处理网络
pip install torchvision 然后打开一个终端，导入torchvision.models模型包
from torchvision import models 导入MobileNetV3并初始化 Pytorch为每个网络都提供了一个预训练好的结构，可以自动下载导入
mobilenet = models.mobilenet.mobilenet_v3_small(pretrained=True) mobilenet.eval() 下面就是MobileNetV3的网络结构，从最终输出层可以得知，MobileNetV3会提取1000个特征值
MobileNetV3( (features): Sequential( (0): ConvNormActivation( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): Hardswish() ) (1): InvertedResidual( (block): Sequential( (0): ConvNormActivation( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False) (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (1): SqueezeExcitation( (avgpool): AdaptiveAvgPool2d(output_size=1) (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1)) (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1)) (activation): ReLU() (scale_activation): Hardsigmoid() ) (2): ConvNormActivation( (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=0.</description></item></channel></rss>