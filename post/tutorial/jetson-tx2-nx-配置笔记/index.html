<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width"><script type=application/javascript src=https://blog.thinkmoe.icu/js/theme-mode.js></script>
<link rel=stylesheet href=https://blog.thinkmoe.icu/css/frameworks.min.css><link rel=stylesheet href=https://blog.thinkmoe.icu/css/github.min.css><link rel=stylesheet href=https://blog.thinkmoe.icu/css/github-style.css><link rel=stylesheet href=https://blog.thinkmoe.icu/css/light.css><link rel=stylesheet href=https://blog.thinkmoe.icu/css/dark.css><link rel=stylesheet href=https://blog.thinkmoe.icu/css/syntax.css><title>Jetson TX2 NX 配置笔记 - 狸猫窝</title><link rel=icon type=image/x-icon href=/images/github.png><meta name=theme-color content="#1e2327"><meta name=description content="Jetson真的好贵"><meta name=keywords content="blog,google analytics"><meta name=robots content="noodp"><link rel=canonical href=https://blog.thinkmoe.icu/post/tutorial/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/><meta name=twitter:card content="summary"><meta name=twitter:title content="Jetson TX2 NX 配置笔记 - 狸猫窝"><meta name=twitter:description content="Jetson真的好贵"><meta name=twitter:site content="https://blog.thinkmoe.icu"><meta name=twitter:creator content><meta name=twitter:image content="https://blog.thinkmoe.icu"><meta property="og:type" content="article"><meta property="og:title" content="Jetson TX2 NX 配置笔记 - 狸猫窝"><meta property="og:description" content="Jetson真的好贵"><meta property="og:url" content="https://blog.thinkmoe.icu/post/tutorial/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/"><meta property="og:site_name" content="Jetson TX2 NX 配置笔记"><meta property="og:image" content="https://blog.thinkmoe.icu"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2023-03-05 22:01:11 +0800 +0800"></head><body><div style=position:relative><header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on"><div class="Header-item mobile-none" style=margin-top:-4px;margin-bottom:-4px><a class=Header-link href=https://blog.thinkmoe.icu><svg class="octicon" height="32" viewBox="0 0 16 16" width="32"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a></div><div class="Header-item d-md-none"><button class="Header-link btn-link js-details-target" type=button onclick='document.querySelector("#header-search").style.display=document.querySelector("#header-search").style.display=="none"?"block":"none"'><svg height="24" class="octicon octicon-three-bars" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button></div><div style=display:none id=header-search class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex"><div class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to"><div class=position-relative><form target=_blank action=https://www.google.com/search accept-charset=utf-8 method=get autocomplete=off><label class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center"><input type=text class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable" name=q placeholder=Search autocomplete=off>
<input type=hidden name=q value=site:https://blog.thinkmoe.icu></label></form></div></div></div><div class="Header-item Header-item--full flex-justify-center d-md-none position-relative"><a class=Header-link href=https://blog.thinkmoe.icu><svg class="octicon octicon-mark-github v-align-middle" height="32" viewBox="0 0 16 16" width="32"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a></div><div class=Header-item style=margin-right:0><a href=javascript:void(0) class="Header-link no-select" onclick=switchTheme()><svg style="fill:var(--color-profile-color-modes-toggle-moon)" class="no-select" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.52208 7.71754c3.05612.0 5.53362-2.47748 5.53362-5.5336C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961 9.95801 1.07727 10.3495.771159 10.6474.99992c1.4679 1.12724 2.4141 2.90007 2.4141 4.89391.0 3.40575-2.7609 6.16667-6.16665 6.16667-2.94151.0-5.40199-2.0595-6.018122-4.81523C.794841 6.87902 1.23668 6.65289 1.55321 6.85451 2.41106 7.40095 3.4296 7.71754 4.52208 7.71754z"/></svg></a></div></header></div><div><main><div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4"><div class=px-0><div class="mb-3 d-flex px-3 px-md-3 px-lg-5"><div class="flex-auto min-width-0 width-fit mr-3"><div class=d-flex><div class="d-none d-md-block"><a class="avatar mr-2 flex-shrink-0" href=https://blog.thinkmoe.icu><img class=avatar-user src=/images/avatar.jpg width=32 height=32></a></div><div class="d-flex flex-column"><h1 class="break-word f3 text-normal mb-md-0 mb-1"><span class=author><a href=https://blog.thinkmoe.icu>无题</a></span><span class=path-divider>/</span><strong class="css-truncate-target mr-1" style=max-width:410px><a href=https://blog.thinkmoe.icu/post/tutorial/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/>Jetson TX2 NX 配置笔记</a></strong></h1><div class="note m-0">Created <relative-time datetime="Sun, 05 Mar 2023 22:01:11 +0800" class=no-wrap>Sun, 05 Mar 2023 22:01:11 +0800</relative-time>
<span class=file-info-divider></span>
Modified <relative-time datetime="Tue, 18 Apr 2023 12:04:12 +0000" class=no-wrap>Tue, 18 Apr 2023 12:04:12 +0000</relative-time></div></div></div></div></div></div></div><div class="container-lg px-3 new-discussion-timeline"><div class="repository-content gist-content"><div><div class="js-gist-file-update-container js-task-list-container file-box"><div id=file-pytest class="file my-2"><div id=post-header class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style=z-index:2><div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto"><div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0"><summary id=toc-toggle onclick=clickToc() class="btn btn-octicon m-0 mr-2 p-2"><svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered"><path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zm0 5a.75.75.0 000 1.5h8.5a.75.75.0 000-1.5h-8.5zM3 8A1 1 0 111 8a1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"/></svg></summary><details-menu class=SelectMenu id=toc-details style="display: none;"><div class="SelectMenu-modal rounded-3 mt-1" style=max-height:340px><div class="SelectMenu-list SelectMenu-list--borderless p-2" style=overscroll-behavior:contain id=toc-list></div></div></details-menu>2305 Words</div><div class="file-actions flex-order-2 pt-0"><a class="muted-link mr-3" href=/tags/%E6%95%99%E7%A8%8B><svg class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M2.5 7.775V2.75a.25.25.0 01.25-.25h5.025a.25.25.0 01.177.073l6.25 6.25a.25.25.0 010 .354l-5.025 5.025a.25.25.0 01-.354.0l-6.25-6.25A.25.25.0 012.5 7.775zm-1.5.0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464.0.91.184 1.238.513l6.25 6.25a1.75 1.75.0 010 2.474l-5.026 5.026a1.75 1.75.0 01-2.474.0l-6.25-6.25A1.75 1.75.0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z"/></svg>教程</a>
<a class="muted-link mr-3" href=/tags/linux><svg class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M2.5 7.775V2.75a.25.25.0 01.25-.25h5.025a.25.25.0 01.177.073l6.25 6.25a.25.25.0 010 .354l-5.025 5.025a.25.25.0 01-.354.0l-6.25-6.25A.25.25.0 012.5 7.775zm-1.5.0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464.0.91.184 1.238.513l6.25 6.25a1.75 1.75.0 010 2.474l-5.026 5.026a1.75 1.75.0 01-2.474.0l-6.25-6.25A1.75 1.75.0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z"/></svg>Linux</a></div></div></div><div class="Box-body px-5 pb-5" style=z-index:1><article class="markdown-body entry-content container-lg"><figure><img src=/images/jetsontx2nx.jpg alt=image><figcaption><p>tx2nx开发板</p></figcaption></figure><p>由于科研的需要，需要在边缘设备上对深度学习模型进行量化测试。实验室内刚好有闲置的Nvidia Jetson TX2开发板，所以就直接拿来测试了</p><p>原本以为在开发板上的配置会比较简单，无非就是从x86平台转换到arm上面，但实际上坑非常多例如前面提到的arm架构，其实在Jetson上面压根不是传统的arm架构，而是从armv8独立分支出来的aarch架构</p><p>虽然坑非常多，但总体上配置流程也非常简洁，基本配置过程也和x86平台上面大致相同，只是在安装的时候需要注意。本文大纲如下</p><ul><li>烧录安装系统</li><li>安装conda虚拟环境</li><li>安装Pytorch和torchvision</li><li>安装torch2trt</li></ul><h2 id=安装系统>安装系统</h2><p>首先需要烧录镜像到开发板中，由于我这块板子在购买的时候代理商就已经烧录好了系统到固件中，因此直接开机即可</p><p>如果是裸板安装，则可以参考知乎的教程进行烧录安装</p><p>连接电源启动开发板，在安装界面中可以选择启用CPU核心的选项，默认是4核，对应的SWAP大小为2GB，可以按照自己的需求进行更改。当然，如果已经安装完了系统也可以在系统中进行修改。</p><p>tx2自带的存储大小非常小只有16GB，按需求进行扩容，我这里是外接了一块128G的SSD硬盘</p><h2 id=安装conda虚拟环境>安装conda虚拟环境</h2><p>按照本人的习惯，需要一个虚拟环境用于区分不同项目的环境，在tx2也不例外。这里就出现了第一个坑，那就是官方的conda并不能在tx2上完美运行！
就算你下载的是aarch架构的脚本，你在安装过程中也可能报错，又或者即使安装成功你在创建虚拟环境选择低版本的Python时也会出现错误</p><p>为了解决这个问题，我们需要使用一个修改版的conda，那就是<a href=https://github.com/conda-forge/miniforge>Mambaforge</a>。从官方的<a href=https://github.com/conda-forge/miniforge/releases>Release</a>中下载所需要的脚本文件(<strong>注意得是aarch架构的文件！</strong>)，安装方式则和普通版本的conda如出一辙，需要注意的是安装的位置需要选择一个容量更大的硬盘上面</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>wget https://github.com/conda-forge/miniforge/releases/download/22.11.1-4/Mambaforge-22.11.1-4-Linux-aarch64.sh
</span></span><span class=line><span class=cl>sh Mambaforge-22.11.1-4-Linux-aarch64.sh
</span></span></code></pre></div><p>随后创建你的第一个环境吧</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>conda create -n hello <span class=nv>python</span><span class=o>=</span>3.6
</span></span><span class=line><span class=cl>conda activate hello
</span></span></code></pre></div><h2 id=安装pytorch和torchvision>安装Pytorch和torchvision</h2><p>在安装Pytorch前，你需要安装Jetson的CUDA环境，默认情况下是没有的，当然在Nvidia自家产品上安装CUDA环境非常简单，不像Linux那样惹人厌。安装只需要一条命令即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo apt install nvidia-jetpack
</span></span></code></pre></div><p>这时，查看<code>/usr/local</code>中应该就会出现对应的CUDA环境了，Jetpack会帮助你安装CUDA工具包、TensorRT和其他工具，你可以通过<code>jetson_release</code>来查看当前安装的CUDA版本</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>(</span>base<span class=o>)</span> tx2-1@tx2-1-desktop:/usr/local$ jetson_release
</span></span><span class=line><span class=cl>Software part of jetson-stats 4.1.5 - <span class=o>(</span>c<span class=o>)</span> 2023, Raffaello Bonghi
</span></span><span class=line><span class=cl>Model: lanai-3636 - Jetpack 4.6.1 <span class=o>[</span>L4T 32.7.1<span class=o>]</span>
</span></span><span class=line><span class=cl>NV Power Mode: MAXP_CORE_ARM - Type: <span class=m>3</span>
</span></span><span class=line><span class=cl>jtop:
</span></span><span class=line><span class=cl> - Version: 4.1.5
</span></span><span class=line><span class=cl> - Service: Active
</span></span><span class=line><span class=cl>Libraries:
</span></span><span class=line><span class=cl> - CUDA: 10.2.300
</span></span><span class=line><span class=cl> - cuDNN: 8.2.1.32
</span></span><span class=line><span class=cl> - TensorRT: 8.2
</span></span><span class=line><span class=cl> - VPI: 1.2.3
</span></span><span class=line><span class=cl> - OpenCV: 4.1.1 - with CUDA: NO
</span></span></code></pre></div><p>此时，你也可以将CUDA的环境添加到终端中，为后续编译做准备</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># $HOME/.bashrc</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CUDA_HOME</span><span class=o>=</span>/usr/local/cuda
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$CUDA_HOME</span>/bin
</span></span></code></pre></div><p>接下来就要开始安装Pytorch了，注意的是在Jetson设备上并不能像传统conda环境那样直接通过conda或pip安装，需要到Nvidia官方下载对应的安装包。而torchvision也需要自己手动编译安装或下载第三方编译好的包进行安装。以下流程均来自<a href=https://forums.developer.nvidia.com/t/pytorch-for-jetson/72048>官方教程</a></p><ol><li>安装Pytorch
在这里，由于虚拟环境选择的Python版本为3.6，而最高支持3.6版本的Pytorch版本为1.8.0，所以这里安装1.8.0版本</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>wget https://nvidia.box.com/shared/static/p57jwntv436lfrd78inwl7iml6p13fzh.whl -O torch-1.8.0-cp36-cp36m-linux_aarch64.whl
</span></span><span class=line><span class=cl>sudo apt-get install python3-pip libopenblas-base libopenmpi-dev libomp-dev
</span></span><span class=line><span class=cl>conda activate hello
</span></span><span class=line><span class=cl>pip install cython <span class=nv>numpy</span><span class=o>==</span>1.19.4 torch-1.8.0-cp36-cp36m-linux_aarch64.whl
</span></span></code></pre></div><p>注意，这里<code>numpy</code>选择安装<code>1.19.4</code>版本，默认的<code>1.19.5</code>版本会出现莫名其妙的bug</p><ol start=2><li>安装torchvision<br>安装torchvison需要注意所安装的torch版本，对应列表如下</li></ol><pre tabindex=0><code>PyTorch v1.0 - torchvision v0.2.2
PyTorch v1.1 - torchvision v0.3.0
PyTorch v1.2 - torchvision v0.4.0
PyTorch v1.3 - torchvision v0.4.2
PyTorch v1.4 - torchvision v0.5.0
PyTorch v1.5 - torchvision v0.6.0
PyTorch v1.6 - torchvision v0.7.0
PyTorch v1.7 - torchvision v0.8.1
PyTorch v1.8 - torchvision v0.9.0
PyTorch v1.9 - torchvision v0.10.0
PyTorch v1.10 - torchvision v0.11.1
PyTorch v1.11 - torchvision v0.12.0
PyTorch v1.12 - torchvision v0.13.0
</code></pre><p>我们先看看自行编译安装方式，首先确认所需要的版本，这里为<code>v0.9.0</code>，然后按照下述过程进行安装</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libavcodec-dev libavformat-dev libswscale-dev
</span></span><span class=line><span class=cl>git clone --branch 0.9.0 https://github.com/pytorch/vision torchvision
</span></span><span class=line><span class=cl><span class=nb>cd</span> torchvision
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>BUILD_VERSION</span><span class=o>=</span>0.9.0
</span></span><span class=line><span class=cl>python3 setup.py install --user
</span></span></code></pre></div><p>如果你一切顺利的话，通过<code>pip list | grep torch</code>则可以看到对应的安装文件了，但是本人运气不咋行，在编译中遇到<code>nvcc</code>的错误，什么找不到目标文件之类的，但是也没有其他错误信息，让我非常头疼</p><p>幸运的是，在谷歌上搜到别人为nano编译好了的torchvision。虽然是在nano编译的，但是都是aarch架构应该可以用吧，实际上也确实可以用，<a href=https://qengineering.eu/install-pytorch-on-jetson-nano.html>参考链接</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev
</span></span><span class=line><span class=cl>sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev
</span></span><span class=line><span class=cl>pip install pillow gdown
</span></span><span class=line><span class=cl>gdown https://drive.google.com/uc?id<span class=o>=</span>1BdvXkwUGGTTamM17Io4kkjIT6zgvf4BJ
</span></span><span class=line><span class=cl>pip install torchvision-0.9.0a0+01dfa8e-cp36-cp36m-linux_aarch64.whl
</span></span><span class=line><span class=cl>pip list <span class=p>|</span> grep torch
</span></span><span class=line><span class=cl>torch               1.8.0
</span></span><span class=line><span class=cl>torch2trt           0.4.0 <span class=c1># 这个后面会进行安装</span>
</span></span><span class=line><span class=cl>torchvision         0.9.0a0+01dfa8e
</span></span></code></pre></div><p>ok，这就安装完事了，非常简单</p><p>最后打开终端测试是否安装成功</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_avaliable</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=kc>True</span>
</span></span></code></pre></div><h2 id=安装torch2trt>安装torch2trt</h2><p>安装torch2trt的过程非常简单，但也有两个点需要注意</p><p>首先，我们可以发现在上面安装<code>jetpack</code>的时候可以发现已经安装好了<code>TensorRT</code>（甚至<code>docker</code>），但是安装包并不存在于虚拟环境中，而我们并不想要在重新安装一遍这玩意，因此需要对其进行复用，不然后续编译<code>torch2trt</code>时会直接报错（</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PYTHONPATH</span><span class=o>=</span><span class=nv>$PYTHONPATH</span>:/usr/lib/python3.6/dist-packages <span class=c1># 目录按照实际情况更改</span>
</span></span></code></pre></div><p>这时你再到虚拟环境的终端中测试python是否能正常导入tensorrt</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorrt</span>
</span></span></code></pre></div><p>如果一切正常就可以进行下一步的安装了，首先需要clone所需要的仓库</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>git clone https://github.com/NVIDIA-AI-IOT/torch2trt
</span></span><span class=line><span class=cl><span class=nb>cd</span> torch2trt
</span></span></code></pre></div><p>在这里我们直接选择最新版本，避免和tensorrt新api冲突</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>git checkout v0.4.0
</span></span></code></pre></div><p>随后就可以直接进行安装了，如果安装过程中碰到缺少包的情况直接pip安装即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>python setup.py install
</span></span><span class=line><span class=cl>pip list <span class=p>|</span> grep torch
</span></span><span class=line><span class=cl>torch               1.8.0
</span></span><span class=line><span class=cl>torch2trt           0.4.0 <span class=c1># 这个后面会进行安装</span>
</span></span><span class=line><span class=cl>torchvision         0.9.0a0+01dfa8e
</span></span></code></pre></div><h2 id=结语>结语</h2><p>总的来说Tx2的配置没有我想象中的简单但也没有那么复杂，Nvidia社区中有大量的解决方案（虽然nano居多）仔细谷歌也都可以寻找到答案。我在测试了几个开源的项目后发现TX2的性能也还不错，不过CPU非常垃圾，后续也会写写关于开源项目如何在TX2上测试的例子，更好的理解和熟悉这块开发板</p></article></div></div></div></div></div></div></main></div><script type=application/javascript src=https://blog.thinkmoe.icu/js/toc.js></script>
<link rel=stylesheet href=https://blog.thinkmoe.icu/css/toc.css><div class="footer container-xl width-full p-responsive"><div class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light"><a aria-label=Homepage title=GitHub class="footer-octicon d-none d-lg-block mr-lg-4" href=https://blog.thinkmoe.icu><svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M8 0C3.58.0.0 3.58.0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38.0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95.0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12.0.0.67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15.0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48.0 1.07-.01 1.93-.01 2.2.0.21.15.46.55.38A8.013 8.013.0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a><ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0"><li class="mr-3 mr-lg-0">This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</li></ul></div><div class="d-flex flex-justify-center pb-6"><span class="f6 text-gray-light"></span></div></div></body><script type=application/javascript src=https://blog.thinkmoe.icu/js/github-style.js></script></html>