<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>狸猫窝</title><link>https://blog.thinkmoe.icu/</link><description>Recent content on 狸猫窝</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 05 Mar 2023 22:01:11 +0800</lastBuildDate><atom:link href="https://blog.thinkmoe.icu/index.xml" rel="self" type="application/rss+xml"/><item><title>Jetson TX2 NX 配置笔记</title><link>https://blog.thinkmoe.icu/posts/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 05 Mar 2023 22:01:11 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/jetson-tx2-nx-%E9%85%8D%E7%BD%AE%E7%AC%94%E8%AE%B0/</guid><description>Jetson真的好贵啊&amp;gt; &amp;lt;
tx2nx开发板
由于科研的需要，需要在边缘设备上对深度学习模型进行量化测试。实验室内刚好有闲置的Nvidia Jetson TX2开发板，所以就直接拿来测试了
原本以为在开发板上的配置会比较简单，无非就是从x86平台转换到arm上面，但实际上坑非常多例如前面提到的arm架构，其实在Jetson上面压根不是传统的arm架构，而是从armv8独立分支出来的aarch架构
虽然坑非常多，但总体上配置流程也非常简洁，基本配置过程也和x86平台上面大致相同，只是在安装的时候需要注意。本文大纲如下
烧录安装系统 安装conda虚拟环境 安装Pytorch和torchvision 安装torch2trt 安装系统 首先需要烧录镜像到开发板中，由于我这块板子在购买的时候代理商就已经烧录好了系统到固件中，因此直接开机即可
如果是裸板安装，则可以参考知乎的教程进行烧录安装
连接电源启动开发板，在安装界面中可以选择启用CPU核心的选项，默认是4核，对应的SWAP大小为2GB，可以按照自己的需求进行更改。当然，如果已经安装完了系统也可以在系统中进行修改。
tx2自带的存储大小非常小只有16GB，按需求进行扩容，我这里是外接了一块128G的SSD硬盘
安装conda虚拟环境 按照本人的习惯，需要一个虚拟环境用于区分不同项目的环境，在tx2也不例外。这里就出现了第一个坑，那就是官方的conda并不能在tx2上完美运行！ 就算你下载的是aarch架构的脚本，你在安装过程中也可能报错，又或者即使安装成功你在创建虚拟环境选择低版本的Python时也会出现错误
为了解决这个问题，我们需要使用一个修改版的conda，那就是Mambaforge。从官方的Release中下载所需要的脚本文件(注意得是aarch架构的文件！)，安装方式则和普通版本的conda如出一辙，需要注意的是安装的位置需要选择一个容量更大的硬盘上面
wget https://github.com/conda-forge/miniforge/releases/download/22.11.1-4/Mambaforge-22.11.1-4-Linux-aarch64.sh sh Mambaforge-22.11.1-4-Linux-aarch64.sh 随后创建你的第一个环境吧
conda create -n hello python=3.6 conda activate hello 安装Pytorch和torchvision 在安装Pytorch前，你需要安装Jetson的CUDA环境，默认情况下是没有的，当然在Nvidia自家产品上安装CUDA环境非常简单，不像Linux那样惹人厌。安装只需要一条命令即可
sudo apt install nvidia-jetpack 这时，查看/usr/local中应该就会出现对应的CUDA环境了，Jetpack会帮助你安装CUDA工具包、TensorRT和其他工具，你可以通过jetson_release来查看当前安装的CUDA版本
(base) tx2-1@tx2-1-desktop:/usr/local$ jetson_release Software part of jetson-stats 4.1.5 - (c) 2023, Raffaello Bonghi Model: lanai-3636 - Jetpack 4.6.1 [L4T 32.7.1] NV Power Mode: MAXP_CORE_ARM - Type: 3 jtop: - Version: 4.</description></item><item><title>记一次Python引入第三方源码包的解决方式</title><link>https://blog.thinkmoe.icu/posts/%E8%AE%B0%E4%B8%80%E6%AC%A1python%E5%BC%95%E5%85%A5%E7%AC%AC%E4%B8%89%E6%96%B9%E6%BA%90%E7%A0%81%E5%8C%85%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/</link><pubDate>Tue, 16 Aug 2022 17:13:03 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/%E8%AE%B0%E4%B8%80%E6%AC%A1python%E5%BC%95%E5%85%A5%E7%AC%AC%E4%B8%89%E6%96%B9%E6%BA%90%E7%A0%81%E5%8C%85%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/</guid><description>Python虽然挺好用的，但也挺难用的
众所周知，Python由于其“先进”的包管理功能，让你几乎可以通过一条命令安装所有打包好的第三方包。但是当我们想从第三方的项目里面引入少许函数时，这种方式就行不得通了.
例如我想从一个Pytorch项目中将模型定义的函数引入（说的就是你Yolo）到我自己的函数中，项目目录结构如下：
. ├── main.py ├── src │ └── module │ ├── a.py │ ├── __init__.py │ └── __pycache__ │ ├── a.cpython-38.pyc │ └── __init__.cpython-38.pyc └── thirdparty └── codes ├── modules │ ├── b.py │ ├── __init__.py │ ├── __pycache__ │ │ ├── b.cpython-38.pyc │ │ ├── c.cpython-38.pyc │ │ └── __init__.cpython-38.pyc │ └── submodule │ ├── c.py │ └── __pycache__ │ └── c.cpython-38.pyc ├── __pycache__ │ └── b.</description></item><item><title>WSL2更改桥接网络</title><link>https://blog.thinkmoe.icu/posts/wsl2%E6%9B%B4%E6%94%B9%E6%A1%A5%E6%8E%A5%E7%BD%91%E7%BB%9C/</link><pubDate>Thu, 05 May 2022 13:34:24 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/wsl2%E6%9B%B4%E6%94%B9%E6%A1%A5%E6%8E%A5%E7%BD%91%E7%BB%9C/</guid><description>WSL2默认情况下网络是处于NAT模式之下，在正常情况下联网是没有问题的，但是遇到一些特殊情况下时NAT网络就非常的鸡肋。 例如，NAT的WSL2并不能直接使用宿主机的代理服务器，需要手动获取本机IP和宿主机在WSL2中的IP地址才能进行局域网连接。 在例如本人需要在WSL2中远程连接实验室车辆上的ROS2节点，由于NAT的存在导致小车上ROS2节点发布的Topic并不能在WSL2中接收到，因此我需要将WSL2默认的NAT网络 更改为桥接网络，这样在不影响宿主机上网的同时也能分配给WSL2一个局域网地址
本方法需要通过Hyper-V虚拟网卡进行，因此首先需要安装并开启Windows的Hyper-V功能
修改桥接网络步骤如下(以下步骤均在管理员模式的Powershell中进行)：
从Powershell中开启wsl，生成网卡 wsl.exe 如果只是开机自启的wsl会出现找不到WSL网卡的错误 2. 获取网卡信息
Get-NetAdapter 运行之后可以查看当前Windows中的网卡设备，例如WLAN 3. 桥接网卡 选择WSL2需要桥接的网卡设备，以WLAN为例
Set-VMSwitch WSL -NetAdapterName WLAN 配置WSL2地址 这时，已经将WSL2的网卡桥接到物理网卡之上，需要手动配置WSL2的静态地址，假设路由器的网关为192.168.8.1，需要配置静态地址为192.168.8.123，则可以按照以下步骤进行配置(在WSL2中进行) sudo ip addr flush dev eth0 sudo ip addr add 192.168.8.123/24 dev eth0 sudo ip route add 0.0.0.0/0 via 192.168.8.1 dev eth0 更改过后还需手动更改DNS地址
# /etc/resolv.conf nameserver 192.168.8.1 保存并退出
以上就完成了WSL2的桥接网络配置，需要注意的是，每次都需要手动更新DNS文件，如果连接到别的路由器之下还需要手动更新静态地址和网关地址</description></item><item><title>Ubuntu20.04 Install Opencv3.1.0 With Python3</title><link>https://blog.thinkmoe.icu/posts/ubuntu20.04-install-opencv3.1.0-with-python3/</link><pubDate>Mon, 28 Mar 2022 16:40:37 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/ubuntu20.04-install-opencv3.1.0-with-python3/</guid><description>安装依赖 Ubuntu20.04需要安装以下依赖
sudo apt install -y --no-install-recommends \ build-essential \ git \ wget \ unzip \ yasm \ pkg-config \ libswscale-dev \ libtbb2 \ libtbb-dev \ libjpeg-dev \ libpng-dev \ libtiff-dev \ libopenjp2-7-dev \ libavformat-dev \ libpq-dev \ libgtk2.0-dev libgtk-3-dev \ libgphoto2-dev \ libtiff5-dev libjpeg8-dev libpng-dev cmake make \ libavformat-dev libavcodec-dev libswscale-dev libdc1394-22-dev libavresample-dev \ libxine2-dev libv4l-dev \ libatlas-base-dev \ libfaac-dev libmp3lame-dev libtheora-dev \ libvorbis-dev libxvidcore-dev \ libeigen3-dev \ libgstreamer1.0-0 gstreamer1.</description></item><item><title>ROS2虚拟环境配置指南</title><link>https://blog.thinkmoe.icu/posts/ros2%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</link><pubDate>Tue, 22 Feb 2022 14:35:57 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/ros2%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</guid><description>在使用CARLA的ROS2包的过程中，需要导入torch对图像进行处理，按照正常情况下，激活conda环境之后应该就能够直接使用虚拟环境中安装的第三方包，但是在ROS2启动的过程中却提示torch not found的错误
开始怀疑是conda环境导致的，于是更换为官方的venv，但是在安装完依赖后编译启动显示还是同样的错误。
在Github搜索后发现，原来通过colcon编译的ROS2节点在启动的时候默认使用系统环境的Python环境运行，并不会加载编译时使用的虚拟环境，因此在虚拟环境中安装的第三方依赖也不会正常使用了。根据rotu的说法，由于ROS2节点的运行文件是由colcon编译生成，而在colcon编译过程中解释器的选择是写死为系统环境的Python的，那是不是ROS2就用不了虚拟环境运行呢？
当然不是，根据上个链接的说法，可以通过修改ROS2的配置文件来间接的让系统使用虚拟环境中的Python解释器，按照theunkn0wn1的描述，总共分为4步
修改setup.cfg文件，添加如下配置 # src/{node}/setup.cfg [build_scripts] executable = /usr/bin/env python3 创建虚拟环境 在创建虚拟环境时，需要将系统环境中的ROS2包链接到虚拟环境中 python3 -m venv venv --system-site-packages --symlinks 这时在目录中会生成venv文件
激活ros2环境配置和虚拟环境配置 source /opt/ros/foxy/setup.zsh source ./venv/bin/activate colcon build并运行 colcon build ros2 run package_name node_name 这时就可以使用到虚拟环境中的第三方包了</description></item><item><title>使用Pytorch预训练网络获取图片特征</title><link>https://blog.thinkmoe.icu/posts/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87%E7%89%B9%E5%BE%81/</link><pubDate>Fri, 17 Dec 2021 17:52:42 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C%E8%8E%B7%E5%8F%96%E5%9B%BE%E7%89%87%E7%89%B9%E5%BE%81/</guid><description>由于Carla训练过程中需要使用到图像数据，而通常深度强化学习(DRL)算法中，输入的数据都为一个 向量(Vector)，如果需要使用图像这种二维数据，通常的做法是使用一个CNN网络，提取图像的特征， 将二维数据转化为一维向量数据，这样就能够直接使用现有的DRL算法
例如在stable_baseline3中，支持MLP、CNN和 多种不同类型观测对象混合输入。对于图像数据，都使用了一个基于CNN深度卷积网络来提取特征。
在pytorch中已经有了很多优秀的CNN特征提取网络，在这里我将会使用到MobileNetV3这个网络用 于提取Carla的摄像头图片特征。
读取模型 首先需要安装torchvision这个包，里面包含了现有非常流行的图像处理网络
pip install torchvision 然后打开一个终端，导入torchvision.models模型包
from torchvision import models 导入MobileNetV3并初始化 Pytorch为每个网络都提供了一个预训练好的结构，可以自动下载导入
mobilenet = models.mobilenet.mobilenet_v3_small(pretrained=True) mobilenet.eval() 下面就是MobileNetV3的网络结构，从最终输出层可以得知，MobileNetV3会提取1000个特征值
MobileNetV3( (features): Sequential( (0): ConvNormActivation( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): Hardswish() ) (1): InvertedResidual( (block): Sequential( (0): ConvNormActivation( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False) (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (1): SqueezeExcitation( (avgpool): AdaptiveAvgPool2d(output_size=1) (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1)) (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1)) (activation): ReLU() (scale_activation): Hardsigmoid() ) (2): ConvNormActivation( (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(16, eps=0.</description></item><item><title>Docker多级构建指南</title><link>https://blog.thinkmoe.icu/posts/docker%E5%A4%9A%E7%BA%A7%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97/</link><pubDate>Wed, 25 Aug 2021 09:01:12 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/docker%E5%A4%9A%E7%BA%A7%E6%9E%84%E5%BB%BA%E6%8C%87%E5%8D%97/</guid><description>多级构建让你的容器更小巧~
在构建Docker镜像的时候经常发现构建出来的容器大小非常的大，而我本地编译出来的二进制文件也不过26MB左右而Docker容器居然有120MB！ 问题出现在哪里了呢？我们一步一步从最起始的地方开始看起
构建方式 Docker容器的构建方法我个人常用以下几种
本地打包二进制后直接放入Docker中运行 容器内打包直接运行 第一种的方式就是在本地编译好要执行的文件之后放入容器之中运行，这种方式无疑是最简单的方法也是最容易理解的方法。 但这种方法仔细一想就会发现有很多问题，假设我们需要在Windows机器编译Linux版本的容器内运行要怎么办呢？ 除此之外，假设我们换了一台机器也需要编译一份Docker镜像时，本地没有对应的编译工具要如何解决呢？ 为了应对上述问题，也就有了第二种方法。
第二种的方式就是将代码放在容器内部编译，这样既解决了编译环境问题也解决了编译平台的问题。 但第二种方法带来的问题就是我今天要说的，那就是打包后的镜像体积过大，完全不如第一种打包出来的镜像。 这是因为，第一种只是将二进制文件放入容器内直接运行，而第二种还添加了项目的源代码文件，除此之外，还有一堆用于 编译二进制文件的工具在镜像之中，因此打包出来的镜像体积会非常巨大。 那有没有一种方法既能随意构建又不产生大体积的镜像呢？那就要谈谈Docker的多级构建了。
多级构建 Docker的多级构建也就是常说的multi-stage build，你可以通过指定多个stage分别完成不同的任务最后合在一起完成最终的构建。
例如有一个Go的项目，我们可以在stage1阶段进行编译操作，而在stage2阶段进行运行操作，这样就相当于构建1和2相结合，完成最后的构建。
多级构建其实非常简单，其精髓就在于一个命令那就是COPY，这个命令不仅仅可以将本地文件拷贝至Docker的build进程上下文中，还可以在多个stage中 进行文件的复制，而ADD命令则只能用于前者，因此我通常在第一级构建时使用ADD命令将所有的源代码复制到Docker上下文中后，使用COPY应对其他层级的构建。COPY的参数非常简单
COPY --from=stage source dest 其中from就是用于表明从哪个stage中复制文件，不添加该参数则默认从宿主机中复制文件。stage可以用数字表示从第几级复制(从0开始)，也可以用字符串来指定层级复制但需要对层级进行命名
# builder stage FROM x as builder # final stage FROM x as final COPY --from=builder /abc /abc COPY --from=0 /abc/abc 实战 以我的Yuki为例，该项目由React和Go组成，其中Go将会提供服务器提供前端接口。
首先分析阶层，我们需要编译两个项目，其中是React另一个是Go，并且Go的编译需要依赖于React。因此很容易得出，以下顺序
编译React 编译Go 运行 为了让编译出来的容器尽可能的小，我们在选取构建容器时也尽量选择小的容器来进行编译例如我最喜欢的alpine。因此在Docker Hub中寻找关于nodejs和golang的alpine版本，由于原版golang的alpine版本不附带gcc因此我选择了第三方的容器tetafro/golang-gcc。而提供运行环境的容器我也选择了alpine:3.14
NodeJS: node:14.17.5-alpine(117MB) Golang: tetafro/golang-gcc:1.16-alpine(425MB) Runtime: alpine:3.14(5.6MB) 在选择完构建容器后就可以正式构建自己的程序了，首先是React的打包，注意的是如果将node_modules文件一并Add的话将不会再拉取一遍不符合我们的要求，因此需要提请编写一个类似于.gitignore文件的.dockerignore文件，例如我使用的
cat ./dockerignore release data web/node_modules web/dist .</description></item><item><title>Ubuntu Server 20.04 设置IP和网关地址</title><link>https://blog.thinkmoe.icu/posts/ubuntu-server-20.04-%E8%AE%BE%E7%BD%AEip%E5%9C%B0%E5%9D%80%E5%92%8C%E7%BD%91%E5%85%B3%E5%9C%B0%E5%9D%80/</link><pubDate>Thu, 19 Aug 2021 15:36:40 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/ubuntu-server-20.04-%E8%AE%BE%E7%BD%AEip%E5%9C%B0%E5%9D%80%E5%92%8C%E7%BD%91%E5%85%B3%E5%9C%B0%E5%9D%80/</guid><description>Ubuntu从20.04版本开始使用netplan对网络进行管理，百度上使用的/etc/network/interfaces文件已不再适用，需要修改netplan配置文件进行更新
修改配置文件 netplan的配置文件存放在/etc/netplan中，其中有诸如00-installer-config.yaml的配置文件，打开可以发现
# This is the network config written by &amp;#39;subiquity&amp;#39; network: ethernets: # 网卡名称，我这是虚拟机ens33 ens33: # 是否开启dhcp服务，设置为true后后续的ip和网关可以不用设置 dhcp4: no # IP地址，一般设置一个就行 # 后面的24是子网掩码数目，代表255.255.255.0(11111111.11111111.11111111.00000000) addresses: [192.168.1.106/24] optional: true # 网关地址 gateway4: 192.168.1.253 # dns地址 nameservers: addresses: [233.5.5.5, 192.168.1.253] version: 2 当然，这只是最为基础的网络配置，对于多张网卡还可以进行其他的配置，详情可以参考Netplan官方文档
在修改完文件之后，终端输入以下命令应用配置，Ping外网测试连通性
sudo netplay apply ping 8.8.8.8</description></item><item><title>Websocket关闭错误代码含义</title><link>https://blog.thinkmoe.icu/posts/websocket%E5%85%B3%E9%97%AD%E9%94%99%E8%AF%AF%E4%BB%A3%E7%A0%81%E5%90%AB%E4%B9%89/</link><pubDate>Sat, 07 Aug 2021 15:00:19 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/websocket%E5%85%B3%E9%97%AD%E9%94%99%E8%AF%AF%E4%BB%A3%E7%A0%81%E5%90%AB%E4%B9%89/</guid><description>前情 在处理B站直播的Websocket源时，经常发生连接关闭的错误，最常见的就是close 1006 (abnormal closure): unexpected EOF错误，你说http的状态码还知道，这websocet的状态码还真不知道，于是去查了查记录一下
RFC 6455 根据RFC 6455定义的内容，Websocket在处理关闭时设置了一系列的代码提示。当对一个已经建立的连接进行关闭时，在终端处可能提供一个关闭的解释说明，客户端可以根据这个代码来推测终端关闭连接的原因从而更新客户端连接的代码。当然，终端在关闭时也可以忽视代码直接进行关闭
1000 Normal Closure 1000表明这是一个正常的关闭，表明要传输的数据已经全部完成可以退出
1001 Going Away 1001说明终端可能已经找不到该连接，例如服务可能宕机或浏览器重定向至其他页面
1002 Protocal error 1002说明连接被终端由于消息协议错误而进行强制性退出
1003 Unsupported Data 1003说明终端接受到一个无法处理的数据而进行强制性退出(例如，服务器可能只能够处理文本数据但接受到了二进制数据)
1004 &amp;mdash;Reserved&amp;mdash; 1004字段保留，未来可能用得到
1005 No Status Rcvd 1005是一个保留数据，绝对不允许终端将其设置为关闭时的状态码。It is designated for use in applications expecting a status code to indicate the no stats code was actually present.
1006 Abnormal Closure 1006是一个保留数据，绝对不允许终端将其设置为关闭时的状态码。它是用来指定需要状态码标志连接异常关闭的程序，例如没有发送或接受控制数据
1007 Invalid frame payload data 1007说明终端收到了一个不符合规定的格式数据而关闭连接(例如，non-UTF-8格式的数据包括了一段text消息)
1008 Policy Violation 1008说明终端收到了一个违反服务规则的消息而关闭连接，这是一个多功能状态码，它可以用于没有其他合适的状态码时发送出去例如(1003或1009)或者在有必要隐藏自己的规则信息时发送出去
1009 Message Too Big 1009说明终端收到了一个过大的数据而关闭连接</description></item><item><title>Leetcode 每日一题</title><link>https://blog.thinkmoe.icu/posts/leetcode-%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/</link><pubDate>Fri, 23 Jul 2021 11:50:27 +0800</pubDate><guid>https://blog.thinkmoe.icu/posts/leetcode-%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/</guid><description>2021/7/23 1893 Check if All the Integers in a Range Are Covered (EASY) You are given a 2D integer array ranges and two integers left and right. Each ranges[i] = [starti, endi] represents an inclusive interval between starti and endi.
Return true if each integer in the inclusive range [left, right] is covered by at least one interval in ranges. Return false otherwise.
An integer x is covered by an interval ranges[i] = [starti, endi] if starti &amp;lt;= x &amp;lt;= endi.</description></item></channel></rss>